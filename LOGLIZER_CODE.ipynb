{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loglizer import dataloader, preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_log='D:/UBCO_lecture_materials/BLOCK6/586_LOGFILES/HDFS.log_structured.csv'\n",
    "labels='anomaly_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading D:/UBCO_lecture_materials/BLOCK6/586_LOGFILES/HDFS.log_structured.csv\n",
      "11786 5052\n",
      "Total: 575061 instances, 16838 anomaly, 558223 normal\n",
      "Train: 402542 instances, 11786 anomaly, 390756 normal\n",
      "Test: 172519 instances, 5052 anomaly, 167467 normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train_pre, y_train),(x_test_pre, y_test)=dataloader.load_HDFS(parsed_log,label_file=labels,window='session',train_ratio=0.7,split_type='uniform',save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor\n",
    "feature_extractor=preprocessing.FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Transformed train data summary ======\n",
      "Train data shape: 402542-by-133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform feature extraction on training set\n",
    "x_train=feature_extractor.fit_transform(x_train_pre,term_weighting='tf-idf',normalization=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(feature_extractor.term_weighting)\n",
    "print(feature_extractor.normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Transformed test data summary ======\n",
      "Test data shape: 172519-by-133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform feature extraction on test set\n",
    "x_test=feature_extractor.transform(x_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402542, 133)\n",
      "(402542,)\n",
      "(172519, 133)\n",
      "(172519,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write processed data to CSVs\n",
    "output_dir='OUTPUT/'\n",
    "\n",
    "np.savetxt(output_dir+'x_train.csv',x_train,delimiter=',')\n",
    "np.savetxt(output_dir+'y_train.csv',y_train,delimiter=',')\n",
    "\n",
    "np.savetxt(output_dir+'x_test.csv',x_test,delimiter=',')\n",
    "np.savetxt(output_dir+'y_test.csv',y_test,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CODES FOR TRAINING THE DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"C:/Users/mural/MDS/BLOCK6/586_LOGWORK/loglizer/OUTPUT/x_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.read_csv(\"C:/Users/mural/MDS/BLOCK6/586_LOGWORK/loglizer/OUTPUT/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"C:/Users/mural/MDS/BLOCK6/586_LOGWORK/loglizer/OUTPUT/x_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pd.read_csv(\"C:/Users/mural/MDS/BLOCK6/586_LOGWORK/loglizer/OUTPUT/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999478315306229\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NB = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9959772546791947\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_NB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
